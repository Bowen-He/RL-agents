env_name,Humanoid-v2,string
max_episode,2000,integer
num_layers,3,integer
layer_size,512,integer
num_layers_action_side,1,integer
layer_size_action_side,512,integer
learning_rate,5e-5,float
learning_rate_location_side,0.000005,float
target_network_learning_rate,0.001,float
learning_rate_policy_network,5e-5,float
max_buffer_size,250000,integer
gamma,0.99,float
batch_size,256,integer
num_points,100,integer
reward_clip,20,float
temperature,.1,float
policy_parameter,2.75,float
norm_smoothing,0.00001,float
updates_per_episode,1000,integer
dropout_rate,0.4,float
optimizer,Adam,string
policy_type,gaussian,string
noise,0.05,float
loss_type,MSELoss,string
policy_noise,0.05,float
per_coefficient_lr,True,boolean
regularization_weight,0.001,float
regularize,True,boolean
rank,10,integer
qstar_samples,400,integer
sample_around_output_eval,False,boolean
bootstrap_qvalue_noise_sampled_actions,False,boolean