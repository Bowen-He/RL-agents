env_name,LunarLanderContinuous-v2,string
max_episode,200,integer
num_layers,3,integer
layer_size,512,integer
num_layers_action_side,1,integer
layer_size_action_side,512,integer
learning_rate,0.000025,float
learning_rate_location_side,0.000001,float
learning_rate_policy_network,0.000001,float
target_network_learning_rate,0.005,float
max_buffer_size,500000,integer
gamma,0.99,float
batch_size,256,integer
num_points,100,integer
reward_clip,20,float
temperature,2,float
policy_parameter,2.75,float
norm_smoothing,0.00001,float
updates_per_episode,1000,integer
dropout_rate,0.4,float
optimizer,RMSprop,string
policy_type,e_greedy,string
num_sampled_actions,-1,integer
max_rank_sum,3,integer
qstar_samples,1000,integer
per_coefficient_lr,True,boolean
loss_type,MSELoss,string
policy_noise,0.1,float
q_optimizer,SGD,string
regularize,True,boolean
regularization_weight,0.001,float
rank,3,integer
coefficient_scaling_exponent,1.0,float